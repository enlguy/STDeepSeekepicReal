{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9IJoz_7r5pb"
      },
      "outputs": [],
      "source": [
        "# üöÄ SETUP: Mount Drive and Install Dependencies\n",
        "import os, subprocess, time, requests, threading, re\n",
        "from google.colab import drive\n",
        "\n",
        "# üöÄ Mount Google Drive and install system packages\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!apt -y update && apt -y install -qq build-essential aria2\n",
        "!pip install -q huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Paths\n",
        "drive_path = '/content/drive/MyDrive/koboldcpp_build'\n",
        "local_path = '/content/koboldcpp'\n",
        "\n",
        "# Build or restore KoboldCPP\n",
        "if os.path.exists(drive_path) and os.path.exists(f'{drive_path}/koboldcpp_cublas.so'):\n",
        "    print(\"Restoring KoboldCPP from Drive...\")\n",
        "    !mkdir -p {local_path}\n",
        "    !cp -r {drive_path}/* {local_path}/\n",
        "    print(\"‚úÖ KoboldCPP restored!\")\n",
        "else:\n",
        "    print(\"Building KoboldCPP from scratch...\")\n",
        "    !apt -y install -qq build-essential\n",
        "    !git clone https://github.com/LostRuins/koboldcpp.git\n",
        "    %cd koboldcpp\n",
        "    !make LLAMA_CUBLAS=1 CUDA_DOCKER_ARCH=compute_80,code=sm_80\n",
        "    !mkdir -p {drive_path}\n",
        "    !cp -r /content/koboldcpp/* {drive_path}/\n",
        "    print(\"‚úÖ KoboldCPP built and saved to Drive!\")\n",
        "\n",
        "# Check GPU\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "Dvfim6d2r6gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì• Download GGUF model\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"mradermacher/DeepSeek-R1-Distill-Qwen-32B-Uncensored-GGUF\",\n",
        "    filename=\"DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q5_K_M.gguf\")\n",
        "\n",
        "print(f\"‚úÖ Model downloaded to: {model_path}\")\n"
      ],
      "metadata": {
        "id": "18h9MbA5r85k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üé® Set up Stable Diffusion WebUI with epicRealismXL from Drive\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "if not os.path.exists(\"stable-diffusion-webui\"):\n",
        "    !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git\n",
        "\n",
        "%cd stable-diffusion-webui\n",
        "\n",
        "model_in_drive = \"/content/drive/MyDrive/EpicRealism/epicrealismXL_vxviiCrystalclear.safetensors\"\n",
        "target_path = \"models/Stable-diffusion/epicRealismXL.safetensors\"\n",
        "!mkdir -p models/Stable-diffusion\n",
        "\n",
        "if os.path.exists(model_in_drive):\n",
        "    if not os.path.exists(target_path):\n",
        "        !ln -s \"{model_in_drive}\" \"{target_path}\"\n",
        "        print(\"‚úÖ Model linked from Drive\")\n",
        "    else:\n",
        "        print(\"üîÅ Model already linked\")\n",
        "else:\n",
        "    print(\"‚ùå Model not found in Drive\")\n"
      ],
      "metadata": {
        "id": "4hMZEQb9r9hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì• Download cloudflared\n",
        "!wget -q -O /content/cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x /content/cloudflared"
      ],
      "metadata": {
        "id": "UzgijOo7_Jrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ Launch Stable Diffusion WebUI in background\n",
        "import subprocess, time, requests\n",
        "\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "webui_cmd = [\n",
        "    \"python\", \"launch.py\", \"--deepdanbooru\",\n",
        "    \"--api\", \"--listen\", \"--port\", \"7860\",\n",
        "    \"--skip-torch-cuda-test\", \"--no-half-vae\",\n",
        "    \"--ckpt\", \"models/Stable-diffusion/epicRealismXL.safetensors\"\n",
        "]\n",
        "\n",
        "subprocess.Popen(webui_cmd)\n",
        "print(\"‚úÖ WebUI launched in background. Give it 60‚Äì90 seconds to initialize.\")\n",
        "\n",
        "# Optional: wait for API to become available\n",
        "print(\"‚è≥ Waiting for Stable Diffusion API...\")\n",
        "for i in range(600):\n",
        "    try:\n",
        "        r = requests.get(\"http://127.0.0.1:7860/sdapi/v1/sd-models\", timeout=5)\n",
        "        if r.status_code == 200:\n",
        "            print(\"‚úÖ Stable Diffusion API is ready!\")\n",
        "            break\n",
        "    except:\n",
        "        pass\n",
        "    if i % 30 == 0 and i > 0:\n",
        "        print(f\"Still waiting... ({i}s)\")\n",
        "    time.sleep(1)\n",
        "else:\n",
        "    print(\"‚ùå Stable Diffusion API did not respond in time.\")\n"
      ],
      "metadata": {
        "id": "5aBljra817gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üåê Start Cloudflare tunnel to expose WebUI\n",
        "import subprocess, re\n",
        "\n",
        "tunnel_cmd = \"/content/cloudflared tunnel --url http://localhost:7860 --no-autoupdate\"\n",
        "\n",
        "print(\"‚è≥ Starting Cloudflare tunnel for WebUI...\")\n",
        "tunnel_proc = subprocess.Popen(tunnel_cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "# Print the tunnel URL when it appears\n",
        "for line in tunnel_proc.stdout:\n",
        "    print(line.strip())\n",
        "    match = re.search(r'https://[a-zA-Z0-9\\-]+\\.trycloudflare\\.com', line)\n",
        "    if match:\n",
        "        print(f\"\\nüåê Public WebUI URL: {match.group(0)}\")\n",
        "        break"
      ],
      "metadata": {
        "id": "Tqd5dS86_grb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/koboldcpp\n",
        "\n",
        "!python3 koboldcpp.py \\\n",
        "  --model {model_path} \\\n",
        "  --port 5001 \\\n",
        "  --host 0.0.0.0 \\\n",
        "  --remotetunnel \\\n",
        "  --threads 4 \\\n",
        "  --usecublas \\\n",
        "  --gpulayers 32 \\\n",
        "  --contextsize 4096"
      ],
      "metadata": {
        "id": "SjLL9-2e19Dd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}